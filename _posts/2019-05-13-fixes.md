---
layout: post
title: things never end
---

Turns out I was somewhat wrong about having finished the data visualization. The timeout for Heroku on wait before it fails is a hard 30 seconds, which means calls to DynamoDB can cause timeout before Dash loads if it's a particularly large query (or DynamoDB is just being slow). Have been meaning to offset that by moving the data pull call to queue while Dash loads to prevent Heroku from timing out, but thing is, I can't really test this since I don't have redis set up locally yet. I recently downloaded Virtualbox to have Ubuntu manage the redis service and after a little bit of fiddling (ok, a lot of fiddling, apt-get install redis-server absolutely did not work out of the box on a fresh install of Ubuntu disco - this is not promising for someone who has never used a Linux operating system at all outside of messing around in cygwin to get my dearly beloved xemacs going), only just barely managed to get it going. In the meantime, have trimmed the size of the DynamoDB query to the last 60 days instead of 180 to prevent the timeout. Also fixed a minor bug in which the key I used for DyanamoDB set up was slightly off for a subset of CMO data. Instead of nuclearing the whole table and reuploading all the data, learned to work with DynamoDB by deleting a specific subset of files and then uploading the corrections. Can't just be deleting tables willy nilly in real life, after all. 

Went back to building a visualization, realized that I wanted to show the data at the county level rather than the individual coordinate level, and went back to rewriting a mapper. One thing led to another, and now I'm wondering if it'd make sense to just make a package of the whole mapper instead.

I've been relearning a lot of keyboard shortcuts. A lot of my bad habits are from my xemacs days (the nearly mindless ctrl-x ctrl-s being by far the worst), which have wildly different executions on different editors. 